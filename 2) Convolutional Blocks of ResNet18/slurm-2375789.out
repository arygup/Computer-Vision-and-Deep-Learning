==========================================
SLURM_JOB_ID = 2375789
SLURM_NODELIST = gnode058
SLURM_JOB_GPUS = 2
==========================================
/home2/aryan.g/Q1/2_long.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  train_data = torch.load("train_data.pt")
/home2/aryan.g/Q1/2_long.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  train_labels = torch.load("train_labels.pt")
/home2/aryan.g/Q1/2_long.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_data = torch.load("test_data.pt")
/home2/aryan.g/Q1/2_long.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  test_labels = torch.load("test_labels.pt")
/home2/aryan.g/miniconda3/envs/my_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home2/aryan.g/miniconda3/envs/my_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
wandb: Currently logged in as: aryan-g (smaia3) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home2/aryan.g/Q1/wandb/run-20250212_103521-eeg2qr0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-waterfall-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/aryan-g/custom-resnet-36-mod1
wandb: üöÄ View run at https://wandb.ai/aryan-g/custom-resnet-36-mod1/runs/eeg2qr0k
/home2/aryan.g/miniconda3/envs/my_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home2/aryan.g/miniconda3/envs/my_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Number of classes: 10
Epoch 0: train loss 1.3760, train acc 0.4989, val loss 1.5732, val acc 0.4748
Epoch 1: train loss 0.8743, train acc 0.6886, val loss 1.3662, val acc 0.5691
Epoch 2: train loss 0.6384, train acc 0.7752, val loss 1.0918, val acc 0.6484
Epoch 3: train loss 0.4759, train acc 0.8341, val loss 0.8376, val acc 0.7285
Epoch 4: train loss 0.3535, train acc 0.8776, val loss 0.7545, val acc 0.7628
Epoch 5: train loss 0.2533, train acc 0.9119, val loss 0.8045, val acc 0.7623
Epoch 6: train loss 0.1787, train acc 0.9386, val loss 0.9201, val acc 0.7528
Epoch 7: train loss 0.1197, train acc 0.9593, val loss 0.9524, val acc 0.7506
Epoch 8: train loss 0.0755, train acc 0.9746, val loss 0.8470, val acc 0.7848
Epoch 9: train loss 0.0601, train acc 0.9794, val loss 0.9547, val acc 0.7776
Epoch 10: train loss 0.0659, train acc 0.9766, val loss 0.9094, val acc 0.7872
Epoch 11: train loss 0.0496, train acc 0.9832, val loss 1.1220, val acc 0.7699
Epoch 12: train loss 0.0360, train acc 0.9881, val loss 0.8689, val acc 0.8129
Epoch 13: train loss 0.0261, train acc 0.9911, val loss 1.0659, val acc 0.7873
Epoch 14: train loss 0.0359, train acc 0.9872, val loss 1.5069, val acc 0.7300
Epoch 15: train loss 0.0455, train acc 0.9841, val loss 1.0052, val acc 0.7945
Epoch 16: train loss 0.0391, train acc 0.9867, val loss 1.0412, val acc 0.7920
Epoch 17: train loss 0.0251, train acc 0.9913, val loss 0.9932, val acc 0.8009
Epoch 18: train loss 0.0180, train acc 0.9939, val loss 1.0244, val acc 0.8009
Epoch 19: train loss 0.0156, train acc 0.9952, val loss 1.0039, val acc 0.8023
Epoch 20: train loss 0.0207, train acc 0.9927, val loss 1.3346, val acc 0.7760
Epoch 21: train loss 0.0437, train acc 0.9852, val loss 1.1968, val acc 0.7808
Epoch 22: train loss 0.0302, train acc 0.9895, val loss 1.0245, val acc 0.8068
Epoch 23: train loss 0.0227, train acc 0.9921, val loss 1.0043, val acc 0.8103
Epoch 24: train loss 0.0203, train acc 0.9929, val loss 1.0919, val acc 0.7942
Epoch 25: train loss 0.0201, train acc 0.9927, val loss 1.1187, val acc 0.8042
Epoch 26: train loss 0.0186, train acc 0.9934, val loss 1.0054, val acc 0.8173
Epoch 27: train loss 0.0198, train acc 0.9935, val loss 1.1231, val acc 0.8017
Epoch 28: train loss 0.0214, train acc 0.9925, val loss 1.0370, val acc 0.8114
Epoch 29: train loss 0.0175, train acc 0.9941, val loss 1.0775, val acc 0.8006
custom-resnet-36-mod1 saved successfully.
Epoch 0: train loss 1.0157, train acc 0.6397, val loss 0.9214, val acc 0.6857
Epoch 1: train loss 0.5518, train acc 0.8072, val loss 0.7913, val acc 0.7318
Epoch 2: train loss 0.3734, train acc 0.8681, val loss 0.7808, val acc 0.7555
Epoch 3: train loss 0.2491, train acc 0.9134, val loss 0.7327, val acc 0.7783
Epoch 4: train loss 0.1710, train acc 0.9399, val loss 0.7878, val acc 0.7914
Epoch 5: train loss 0.1289, train acc 0.9549, val loss 0.8903, val acc 0.7722
Epoch 6: train loss 0.0909, train acc 0.9681, val loss 0.8954, val acc 0.7880
Epoch 7: train loss 0.0732, train acc 0.9745, val loss 0.8554, val acc 0.7974
Epoch 8: train loss 0.0630, train acc 0.9785, val loss 0.8100, val acc 0.8117
Epoch 9: train loss 0.0554, train acc 0.9808, val loss 0.8391, val acc 0.8160
Epoch 10: train loss 0.0570, train acc 0.9801, val loss 0.8967, val acc 0.8059
Epoch 11: train loss 0.0380, train acc 0.9869, val loss 0.8374, val acc 0.8196
Epoch 12: train loss 0.0332, train acc 0.9889, val loss 1.1460, val acc 0.7682
Epoch 13: train loss 0.0347, train acc 0.9883, val loss 1.0054, val acc 0.7964
Epoch 14: train loss 0.0414, train acc 0.9860, val loss 0.9342, val acc 0.8112
Epoch 15: train loss 0.0351, train acc 0.9881, val loss 0.9187, val acc 0.8133
Epoch 16: train loss 0.0324, train acc 0.9887, val loss 0.8663, val acc 0.8295
Epoch 17: train loss 0.0297, train acc 0.9898, val loss 0.9304, val acc 0.8091
Epoch 18: train loss 0.0244, train acc 0.9916, val loss 0.8999, val acc 0.8184
Epoch 19: train loss 0.0242, train acc 0.9919, val loss 0.8717, val acc 0.8304
Epoch 20: train loss 0.0329, train acc 0.9890, val loss 0.9896, val acc 0.8045
Epoch 21: train loss 0.0350, train acc 0.9880, val loss 1.0101, val acc 0.8022
Epoch 22: train loss 0.0233, train acc 0.9919, val loss 1.0857, val acc 0.8009
Epoch 23: train loss 0.0166, train acc 0.9942, val loss 0.9467, val acc 0.8231
Epoch 24: train loss 0.0151, train acc 0.9951, val loss 1.0287, val acc 0.8205
Epoch 25: train loss 0.0177, train acc 0.9940, val loss 1.1149, val acc 0.7962
Epoch 26: train loss 0.0319, train acc 0.9892, val loss 1.0449, val acc 0.8105
Epoch 27: train loss 0.0296, train acc 0.9901, val loss 0.9932, val acc 0.8137
Epoch 28: train loss 0.0187, train acc 0.9936, val loss 0.9143, val acc 0.8290
Epoch 29: train loss 0.0175, train acc 0.9943, val loss 1.0521, val acc 0.8073
custom-resnet-36-pretrained-mod2 saved successfully.
Epoch 0: train loss 0.7804, train acc 0.7249, val loss 0.8210, val acc 0.7191
Epoch 1: train loss 0.3687, train acc 0.8728, val loss 0.4939, val acc 0.8318
Epoch 2: train loss 0.2132, train acc 0.9255, val loss 0.4188, val acc 0.8593
Epoch 3: train loss 0.1383, train acc 0.9518, val loss 0.5804, val acc 0.8288
Epoch 4: train loss 0.0969, train acc 0.9665, val loss 0.5057, val acc 0.8480
Epoch 5: train loss 0.0742, train acc 0.9745, val loss 0.5707, val acc 0.8532
Epoch 6: train loss 0.0562, train acc 0.9815, val loss 0.5509, val acc 0.8613
Epoch 7: train loss 0.0378, train acc 0.9875, val loss 0.5394, val acc 0.8683
Epoch 8: train loss 0.0443, train acc 0.9847, val loss 0.5613, val acc 0.8669
Epoch 9: train loss 0.0420, train acc 0.9854, val loss 0.5062, val acc 0.8758
Epoch 10: train loss 0.0287, train acc 0.9903, val loss 0.5727, val acc 0.8692
Epoch 11: train loss 0.0265, train acc 0.9905, val loss 0.5282, val acc 0.8837
Epoch 12: train loss 0.0230, train acc 0.9920, val loss 0.5670, val acc 0.8767
Epoch 13: train loss 0.0282, train acc 0.9901, val loss 0.5653, val acc 0.8775
Epoch 14: train loss 0.0322, train acc 0.9894, val loss 0.6267, val acc 0.8619
Epoch 15: train loss 0.0263, train acc 0.9908, val loss 0.6481, val acc 0.8659
Epoch 16: train loss 0.0250, train acc 0.9916, val loss 0.5613, val acc 0.8777
Epoch 17: train loss 0.0187, train acc 0.9936, val loss 0.6419, val acc 0.8634
Epoch 18: train loss 0.0146, train acc 0.9950, val loss 0.5301, val acc 0.8857
Epoch 19: train loss 0.0142, train acc 0.9955, val loss 0.5676, val acc 0.8822
Epoch 20: train loss 0.0162, train acc 0.9945, val loss 0.5759, val acc 0.8779
Epoch 21: train loss 0.0236, train acc 0.9921, val loss 0.5738, val acc 0.8773
Epoch 22: train loss 0.0266, train acc 0.9908, val loss 0.5568, val acc 0.8805
Epoch 23: train loss 0.0156, train acc 0.9946, val loss 0.6183, val acc 0.8749
Epoch 24: train loss 0.0160, train acc 0.9946, val loss 0.6152, val acc 0.8806
Epoch 25: train loss 0.0156, train acc 0.9943, val loss 0.6303, val acc 0.8753
Epoch 26: train loss 0.0116, train acc 0.9961, val loss 0.5685, val acc 0.8859
Epoch 27: train loss 0.0154, train acc 0.9946, val loss 0.5532, val acc 0.8873
Epoch 28: train loss 0.0205, train acc 0.9933, val loss 0.6383, val acc 0.8772
Epoch 29: train loss 0.0186, train acc 0.9938, val loss 0.5814, val acc 0.8862
custom-resnet-36-pretrained-mod3 saved successfully.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mradiant-waterfall-2[0m at: [34mhttps://wandb.ai/aryan-g/custom-resnet-36-mod1/runs/eeg2qr0k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250212_103521-eeg2qr0k/logs[0m
